# ğŸ“Š Stock Data Cleaning, Aggregation & Streamlit Dashboard

This project performs **data cleaning**, **schema normalization**, **parquet generation**, and **custom aggregations** using **Pandas**, followed by an interactive **Streamlit dashboard** for visualization.

It is designed as a minimal end-to-end workflow for processing stock-market datasets and building dashboards on top of cleaned data.

---

## ğŸ§¹ Data Cleaning Tasks (performed in `prepare_data.py`)

The script performs the following operations using **pandas only**:

### âœ” Load raw CSV  
- Reads all columns as strings  
- Identifies missing values (`""`, `"na"`, `"NA"`, `"null"`, `"-"`)  

### âœ” Normalize schema  
- Converts column headers to `snake_case`  
- Trims all whitespace  
- Unifies text casing (e.g., `"usd"` â†’ `"USD"`)  
- Fixes date format â†’ **YYYY-MM-DD**

### âœ” Convert types properly  
- Dates â†’ `datetime`  
- Prices/volume â†’ numeric  
- Yes/No flags â†’ boolean  

### âœ” Deduplicate rows  
Removes exact duplicates based on key columns.

### âœ” Save cleaned output  
- `cleaned.csv`  
- `cleaned.parquet`

---

## ğŸ“ˆ Aggregations Created (any 3 analyses)

The script generates **three parquet-based analyses** as examples:

---

## ğŸ–¥ï¸ Streamlit Dashboard (app.py)

The dashboard loads **cleaned.parquet** 


### âœ” Used to generate screenshots for submission  
All screenshots are inside the **screenshots/** folder.

---

## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Create the virtual environment  
python -m venv .venv

makefile
Copy code

### 2ï¸âƒ£ Activate it  
**Windows:**
..venv\Scripts\activate


### 3ï¸âƒ£ Install requirements  
pip install pandas numpy streamlit pyarrow matplotlib


### 4ï¸âƒ£ Run the cleaning + aggregation script  
python prepare_data.py


### 5ï¸âƒ£ Run the Streamlit dashboard  
streamlit run app.py


## ğŸ“¸ Screenshots

Screenshots of the Streamlit charts and filters are included 

screenshots/


## âœ¨ Summary

This project demonstrates:

- âœ” Real-world data cleaning using **pandas**  
- âœ” Parquet file generation  
- âœ” Multiple custom aggregations  
- âœ” Interactive dashboard using **Streamlit**  
- âœ” A complete end-to-end mini data pipeline  

It is designed to be simple, readable, and suitable for academic submission.
